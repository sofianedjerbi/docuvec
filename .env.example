# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here

# Embedding Model Configuration
# Options: text-embedding-3-small (default), text-embedding-3-large
EMBED_MODEL=text-embedding-3-small

# Batch size for embedding generation (default: 64)
EMBED_BATCH=64

# Chunking Configuration
MAX_TOKENS=700          # Maximum tokens per chunk
OVERLAP_TOKENS=80       # Token overlap between chunks
MIN_TOKENS=40          # Minimum tokens for valid chunk

# Network Configuration
REQUEST_DELAY=1.0       # Delay between API requests (seconds)
EMBEDDING_DELAY=0.1     # Delay between embedding batches (seconds)
MAX_RETRIES=4          # Maximum retry attempts for failed requests
TIMEOUT=30             # Request timeout (seconds)

# Optional: Proxy Configuration (if needed)
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080